@INPROCEEDINGS{SpectreGuard,
  author={J. {Fustos} and F. {Farshchi} and H. {Yun}},
  booktitle={2019 56th ACM/IEEE Design Automation Conference (DAC)},
  title={Spectre{G}uard: An Efficient Data-centric Defense Mechanism against {S}pectre Attacks},
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={}}

@misc{PLtea-james,
  author={Michael James},
  date={2020-12-03},
  year={2020},
  month={Dec},
  institution={UC San Diego},
  howpublished="personal communication"
}

@book{HarperFoundations,
author = {Harper, Robert},
title = {Practical Foundations for Programming Languages},
year = {2016},
isbn = {1107150302},
publisher = {Cambridge University Press},
address = {USA},
edition = {2nd},
abstract = {This text develops a comprehensive theory of programming languages based on type systems and structural operational semantics. Language concepts are precisely defined by their static and dynamic semantics, presenting the essential tools both intuitively and rigorously while relying on only elementary mathematics. These tools are used to analyze and prove properties of languages and provide the framework for combining and comparing language features. The broad range of concepts includes fundamental data types such as sums and products, polymorphic and abstract types, dynamic typing, dynamic dispatch, subtyping and refinement types, symbols and dynamic classification, parallelism and cost semantics, and concurrency and distribution. The methods are directly applicable to language implementation, to the development of logics for reasoning about programs, and to the formal verification language properties such as type safety. This thoroughly revised second edition includes exercises at the end of nearly every chapter and a new chapter on type refinements.}
}


@inproceedings{SingletonsPaper,
author = {Eisenberg, Richard A. and Weirich, Stephanie},
title = {Dependently Typed Programming with Singletons},
year = {2012},
isbn = {9781450315746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2364506.2364522},
doi = {10.1145/2364506.2364522},
abstract = {Haskell programmers have been experimenting with dependent types for at least a decade, using clever encodings that push the limits of the Haskell type system. However, the cleverness of these encodings is also their main drawback. Although the ideas are inspired by dependently typed programs, the code looks significantly different. As a result, GHC implementors have responded with extensions to Haskell's type system, such as GADTs, type families, and datatype promotion. However, there remains a significant difference between programming in Haskell and in full-spectrum dependently typed languages. Haskell enforces a phase separation between runtime values and compile-time types. Therefore, singleton types are necessary to express the dependency between values and types. These singleton types introduce overhead and redundancy for the programmer.This paper presents the singletons library, which generates the boilerplate code necessary for dependently typed programming using GHC. To compare with full-spectrum languages, we present an extended example based on an Agda interface for safe database access. The paper concludes with a detailed discussion on the current capabilities of GHC for dependently typed programming and suggestions for future extensions to better support this style of programming.},
booktitle = {Proceedings of the 2012 Haskell Symposium},
pages = {117–130},
numpages = {14},
keywords = {singletons, dependently typed programming, haskell, gadts},
location = {Copenhagen, Denmark},
series = {Haskell '12}
}

@article{10.1145/2430532.2364522,
author = {Eisenberg, Richard A. and Weirich, Stephanie},
title = {Dependently Typed Programming with Singletons},
year = {2012},
issue_date = {December 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {12},
issn = {0362-1340},
url = {https://doi.org/10.1145/2430532.2364522},
doi = {10.1145/2430532.2364522},
abstract = {Haskell programmers have been experimenting with dependent types for at least a decade, using clever encodings that push the limits of the Haskell type system. However, the cleverness of these encodings is also their main drawback. Although the ideas are inspired by dependently typed programs, the code looks significantly different. As a result, GHC implementors have responded with extensions to Haskell's type system, such as GADTs, type families, and datatype promotion. However, there remains a significant difference between programming in Haskell and in full-spectrum dependently typed languages. Haskell enforces a phase separation between runtime values and compile-time types. Therefore, singleton types are necessary to express the dependency between values and types. These singleton types introduce overhead and redundancy for the programmer.This paper presents the singletons library, which generates the boilerplate code necessary for dependently typed programming using GHC. To compare with full-spectrum languages, we present an extended example based on an Agda interface for safe database access. The paper concludes with a detailed discussion on the current capabilities of GHC for dependently typed programming and suggestions for future extensions to better support this style of programming.},
journal = {SIGPLAN Not.},
month = sep,
pages = {117–130},
numpages = {14},
keywords = {gadts, haskell, singletons, dependently typed programming}
}

@book{Phantom,
  year = {2003},
  edition = {},
  number = {},
  journal = {},
  pages = {245-262},
  publisher = {},
  school = {},
  title = {Fun with phantom types},
  volume = {},
  author = {Hinze, Ralf},
  editor = {Gibbons, Jeremy and de Moor, Oege},
  series = {}
}

@book{CertProg,
author = {Chlipala, Adam},
title = {Certified Programming with Dependent Types: A Pragmatic Introduction to the Coq Proof Assistant},
year = {2013},
isbn = {0262026651},
publisher = {The MIT Press},
abstract = {The technology of mechanized program verification can play a supporting role in many kinds of research projects in computer science, and related tools for formal proof-checking are seeing increasing adoption in mathematics and engineering. This book provides an introduction to the Coq software for writing and checking mathematical proofs. It takes a practical engineering focus throughout, emphasizing techniques that will help users to build, understand, and maintain large Coq developments and minimize the cost of code change over time. Two topics, rarely discussed elsewhere, are covered in detail: effective dependently typed programming (making productive use of a feature at the heart of the Coq system) and construction of domain-specific proof tactics. Almost every subject covered is also relevant to interactive computer theorem proving in general, not just program verification, demonstrated through examples of verified programs applied in many different sorts of formalizations. The book develops a unique automated proof style and applies it throughout; even experienced Coq users may benefit from reading about basic Coq concepts from this novel perspective. The book also offers a library of tactics, or programs that find proofs, designed for use with examples in the book. Readers will acquire the necessary skills to reimplement these tactics in other settings by the end of the book. All of the code appearing in the book is freely available online.}

}

@article{DepHaskSpec,
author = {Weirich, Stephanie and Voizard, Antoine and de Amorim, Pedro Henrique Azevedo and Eisenberg, Richard A.},
title = {A Specification for Dependent Types in {H}askell},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {ICFP},
url = {https://doi.org/10.1145/3110275},
doi = {10.1145/3110275},
abstract = { We propose a core semantics for Dependent Haskell, an extension of Haskell with full-spectrum dependent types. Our semantics consists of two related languages. The first is a Curry-style dependently-typed language with nontermination, irrelevant arguments, and equality abstraction. The second, inspired by the Glasgow Haskell Compiler's core language FC, is its explicitly-typed analogue, suitable for implementation in GHC. All of our results---chiefly, type safety, along with theorems that relate these two languages---have been formalized using the Coq proof assistant. Because our work is backwards compatible with Haskell, our type safety proof holds in the presence of nonterminating computation. However, unlike other full-spectrum dependently-typed languages, such as Coq, Agda or Idris, because of this nontermination, Haskell's term language does not correspond to a consistent logic. },
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {31},
numpages = {29},
keywords = {Haskell, Dependent Types}
}

@ARTICLE{DOT,
    author = {Emden R. Gansner and Eleftherios Koutsofios and Stephen C. North and Kiem-phong Vo},
    title = {A Technique for Drawing Directed Graphs},
    journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
    year = {1993},
    volume = {19},
    number = {3},
    pages = {214--230}
}

@Book{ BarendregtConversion,
author = { Barendregt, H. P. },
title = { The lambda calculus : its syntax and semantics },
isbn = { 0444854908 },
publisher = { North-Holland },
series = { Studies in Logic and the Foundations of Mathematics },
volume = { 103 },
year = { 1981 },
type = { Book },
chapter = {2},

}
@InProceedings{LooplessBird,
author="Bird, Richard S.",
editor="Uustalu, Tarmo",
title="Loopless Functional Algorithms",
booktitle="Mathematics of Program Construction",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="90--114",
abstract="A loopless algorithm is a procedure for generating a list of values under two restrictions: the first element should be produced in linear time and each subsequent element in constant time. Loopless algorithms arise in the enumeration of combinatorial patterns such as permutations or subsequences. The elements of the generated list describe transitions that determine how the next combinatorial pattern is to be determined from its predecessor. Loopless algorithms were introduced in a procedural setting, and many clever tricks, such as focus pointers, doubly-linked lists and coroutines, have been used to construct them. This paper explores what a purely functional approach can bring to the subject, and calculates loopless functional versions of the Gray code algorithm, the Koda-Ruskey algorithm for listing the prefixes of a forest, and the Johnson-Trotter algorithm for generating permutations. The functional algorithms are completely different from their procedural counterparts, and rely on nothing more fancy than lists, trees and queues.",
isbn="978-3-540-35632-5"
}



@article{DepartedProofs,
author = {Noonan, Matt},
title = {Ghosts of Departed Proofs (Functional Pearl)},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {7},
issn = {0362-1340},
url = {https://doi.org/10.1145/3299711.3242755},
doi = {10.1145/3299711.3242755},
abstract = {Library authors often are faced with a design choice: should a function with preconditions be implemented as a partial function, or by returning a failure condition on incorrect use? Neither option is ideal. Partial functions lead to frustrating run-time errors. Failure conditions must be checked at the use-site, placing an unfair tax on the users who have ensured that the function's preconditions were correctly met.  In this paper, we introduce an API design concept called ``ghosts of departed proofs'' based on the following observation: sophisticated preconditions can be encoded in Haskell's type system with no run-time overhead, by using proofs that inhabit phantom type parameters attached to newtype wrappers. The user expresses correctness arguments by constructing proofs to inhabit these phantom types. Critically, this technique allows the library user to decide when and how to validate that the API's preconditions are met.  The ``ghosts of departed proofs'' approach to API design can achieve many of the benefits of dependent types and refinement types, yet only requires some minor and well-understood extensions to Haskell 2010. We demonstrate the utility of this approach through a series of case studies, showing how to enforce novel invariants for lists, maps, graphs, shared memory regions, and more.},
journal = {SIGPLAN Not.},
month = sep,
pages = {119–131},
numpages = {13},
keywords = {software engineering, API design, higher-rank types, formal methods}
}

@MISC{KleisliArrows,
    author = {Conor McBride},
    title = {Kleisli arrows of outrageous fortune},
    year = {2011}
}

@article{Lifty,
author = {Polikarpova, Nadia and Stefan, Deian and Yang, Jean and Itzhaky, Shachar and Hance, Travis and Solar-Lezama, Armando},
title = {Liquid Information Flow Control},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {ICFP},
url = {https://doi.org/10.1145/3408987},
doi = {10.1145/3408987},
abstract = {We present Lifty, a domain-specific language for data-centric applications that manipulate sensitive data. A Lifty programmer annotates the sources of sensitive data with declarative security policies, and the language statically and automatically verifies that the application handles the data according to the policies. Moreover, if verification fails, Lifty suggests a provably correct repair, thereby easing the programmer burden of implementing policy enforcing code throughout the application.  The main insight behind Lifty is to encode information flow control using liquid types, an expressive yet decidable type system. Liquid types enable fully automatic checking of complex, data dependent policies, and power our repair mechanism via type-driven error localization and patch synthesis. Our experience using Lifty to implement three case studies from the literature shows that (1) the Lifty policy language is sufficiently expressive to specify many real-world policies, (2) the Lifty type checker is able to verify secure programs and find leaks in insecure programs quickly, and (3) even if the programmer leaves out all policy enforcing code, the Lifty repair engine is able to patch all leaks automatically within a reasonable time.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {105},
numpages = {30},
keywords = {program synthesis, liquid types, information flow control}
}

@inproceedings{HistoryOfHaskell,
author = {Hudak, Paul and Hughes, John and Peyton Jones, Simon and Wadler, Philip},
title = {A History of Haskell: Being Lazy with Class},
year = {2007},
isbn = {9781595937667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1238844.1238856},
doi = {10.1145/1238844.1238856},
abstract = {This paper describes the history of Haskell, including its genesis and principles, technical contributions, implementations and tools, and applications and impact.},
booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
pages = {12–1–12–55},
numpages = {55},
location = {San Diego, California},
series = {HOPL III}
}

@inproceedings{DeepAndShallow,
author = {Svenningsson, Josef and Axelsson, Emil},
title = {Combining Deep and Shallow Embedding for {EDSL}},
year = {2012},
isbn = {9783642404467},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-40447-4_2},
doi = {10.1007/978-3-642-40447-4_2},
abstract = {When compiling embedded languages it is natural to use an abstract syntax tree to represent programs. This is known as a deep embedding and it is a rather cumbersome technique compared to other forms of embedding, typically leading to more code and being harder to extend. In shallow embeddings, language constructs are mapped directly to their semantics which yields more flexible and succinct implementations. But shallow embeddings are not well-suited for compiling embedded languages. We present a technique to combine deep and shallow embedding in the context of compiling embedded languages in order to provide the benefits of both techniques. In particular it helps keeping the deep embedding small and it makes extending the embedded language much easier. Our technique also has some unexpected but welcome knock-on effects. It provides fusion of functions to remove intermediate results for free without any additional effort. It also helps to give the embedded language a more natural programming interface.},
booktitle = {Proceedings of the 2012 Conference on Trends in Functional Programming - Volume 7829},
pages = {21–36},
numpages = {16},
location = {St. Andrews, UK},
series = {TFP 2012}
}
